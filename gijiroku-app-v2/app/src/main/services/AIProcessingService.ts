/**
 * AIProcessingService - ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ»ãƒ­ãƒ¼ã‚«ãƒ«çµ±åˆAIå‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹
 * 
 * ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ»å¤–éƒ¨APIä¾å­˜ã‚’æ’é™¤ã—ã€è¨­å®šå¯èƒ½ãªAIå‡¦ç†ç’°å¢ƒã‚’æä¾›
 * - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³å®Œå…¨å¯¾å¿œï¼‰
 * - è¨­å®šå¯èƒ½ãªAPIçµ±åˆï¼ˆGeminiã€OpenAIç­‰ï¼‰
 * - ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç®¡ç†çµ±åˆ
 * - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
 */

import axios from 'axios';
import { SecureStorageService } from './SecureStorageService';
import { WorkspaceService } from './WorkspaceService';
import { DbService } from './DbService';
import { ChunkingService, ChunkingConfig, ChunkingResult, ProcessingProgress } from './ChunkingService';
import * as fs from 'fs/promises';
import * as path from 'path';

export interface AIProcessingOptions {
  provider: 'gemini' | 'openai' | 'offline' | 'mock';
  model?: string;
  temperature?: number;
  maxTokens?: number;
  timeout?: number;
  enableChunking?: boolean;  // åˆ†å‰²å‡¦ç†ã®æœ‰åŠ¹åŒ–
  chunkingConfig?: Partial<ChunkingConfig>;  // åˆ†å‰²è¨­å®š
  onProgress?: (progress: ProcessingProgress) => void;  // é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
}

export interface AIProcessingResult {
  processedText: string;
  provider: string;
  model?: string;
  tokens?: number;
  processingTime: number;
  warnings?: string[];
  chunkingResult?: ChunkingResult;  // åˆ†å‰²å‡¦ç†çµæœ
  totalChunks?: number;  // å‡¦ç†ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯æ•°
}

export interface PromptTemplate {
  id: string;
  title: string;
  category: string;
  description: string;
  is_active: boolean;
  content: string;
}

export class AIProcessingService {
  private static instance: AIProcessingService;
  private secureStorage: SecureStorageService;
  private workspaceService: WorkspaceService;
  private dbService: DbService;
  private chunkingService: ChunkingService;
  private defaultOptions: AIProcessingOptions = {
    provider: 'offline',
    temperature: 0.7,
    maxTokens: 8192,
    timeout: 60000,
    enableChunking: false
  };

  private constructor() {
    this.secureStorage = SecureStorageService.getInstance();
    this.workspaceService = WorkspaceService.getInstance();
    this.dbService = DbService.getInstance();
    this.chunkingService = ChunkingService.getInstance();
  }

  public static getInstance(): AIProcessingService {
    if (!AIProcessingService.instance) {
      AIProcessingService.instance = new AIProcessingService();
    }
    return AIProcessingService.instance;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ã®ãƒ¡ã‚¤ãƒ³APIï¼ˆåˆ†å‰²å‡¦ç†å¯¾å¿œï¼‰
   */
  async processText(
    inputText: string, 
    templateId: string, 
    customPrompt?: string,
    options?: Partial<AIProcessingOptions>
  ): Promise<AIProcessingResult> {
    const startTime = Date.now();
    const processingOptions = { ...this.defaultOptions, ...options };
    const warnings: string[] = [];

    try {
      console.log(`ğŸ¤– AIå‡¦ç†é–‹å§‹ - Provider: ${processingOptions.provider}`);
      console.log(`ğŸ“Š å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ: ${inputText.length}æ–‡å­—`);

      // ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—
      const template = await this.getPromptTemplate(templateId);
      const prompt = customPrompt || template?.content || this.getDefaultPrompt();

      // åˆ†å‰²å‡¦ç†ã®åˆ¤å®š
      const shouldUseChunking = processingOptions.enableChunking && inputText.length > 500;
      
      let result: AIProcessingResult;

      if (shouldUseChunking) {
        console.log('ğŸ”„ åˆ†å‰²å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...');
        result = await this.processWithChunking(inputText, prompt, processingOptions);
      } else {
        console.log('ğŸ”„ é€šå¸¸å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...');
        result = await this.processSingle(inputText, prompt, processingOptions);
      }

      result.processingTime = Date.now() - startTime;
      result.warnings = warnings;

      console.log(`âœ… AIå‡¦ç†å®Œäº† - ${result.processingTime}ms`);
      return result;

    } catch (error) {
      console.error('âŒ AIå‡¦ç†ã‚¨ãƒ©ãƒ¼:', error);
      
      // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
      if (processingOptions.provider !== 'offline') {
        console.log('ğŸ”„ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯...');
        warnings.push(`${processingOptions.provider}å‡¦ç†å¤±æ•—ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†ã«åˆ‡ã‚Šæ›¿ãˆ`);
        
        return await this.processOffline(
          inputText, 
          customPrompt || this.getDefaultPrompt(), 
          { ...processingOptions, provider: 'offline' }
        );
      }
      
      throw error;
    }
  }

  /**
   * åˆ†å‰²å‡¦ç†ã‚’ä½¿ç”¨ã—ãŸAIå‡¦ç†
   */
  private async processWithChunking(
    inputText: string,
    prompt: string,
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    const chunkingConfig = {
      maxChunkSize: options.provider === 'mock' ? 300 : 5000,  // ãƒ¢ãƒƒã‚¯ç”¨300æ–‡å­—ã€æœ¬ç•ªç”¨5000æ–‡å­—
      overlapSize: options.provider === 'mock' ? 50 : 100,
      splitOnSentence: true,
      preserveSpeakers: true,
      ...options.chunkingConfig
    };

    // 1. ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
    console.log('ğŸ”„ Step 1: ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ä¸­...');
    const chunkingResult = await this.chunkingService.chunkText(inputText, chunkingConfig);
    
    // é€²æ—çŠ¶æ³ã®åˆæœŸåŒ–
    const progress: ProcessingProgress = {
      totalChunks: chunkingResult.totalChunks,
      processedChunks: 0,
      currentChunk: 0,
      status: 'processing',
      estimatedTimeLeft: 0,
      errorCount: 0
    };

    options.onProgress?.(progress);

    // 2. å„ãƒãƒ£ãƒ³ã‚¯ã‚’LLMã§å‡¦ç†
    console.log(`ğŸ”„ Step 2: ${chunkingResult.totalChunks}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’LLMå‡¦ç†ä¸­...`);
    const processedChunks: Array<{ chunkId: string; processedText: string }> = [];
    const chunkStartTime = Date.now();
    
    for (let i = 0; i < chunkingResult.chunks.length; i++) {
      const chunk = chunkingResult.chunks[i];
      
      // é€²æ—æ›´æ–°
      progress.currentChunk = i + 1;
      progress.estimatedTimeLeft = this.calculateEstimatedTime(i, chunkingResult.totalChunks, chunkStartTime);
      progress.currentChunkText = chunk.text.substring(0, 50) + '...';
      options.onProgress?.(progress);

      try {
        console.log(`ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ ${i + 1}/${chunkingResult.totalChunks} ã‚’å‡¦ç†ä¸­...`);
        
        const singleResult = await this.processSingle(chunk.text, prompt, options);
        
        processedChunks.push({
          chunkId: chunk.id,
          processedText: singleResult.processedText
        });

        progress.processedChunks = i + 1;
        options.onProgress?.(progress);

        // APIåˆ¶é™ã‚’è€ƒæ…®ã—ãŸé…å»¶
        if (options.provider === 'gemini' || options.provider === 'openai') {
          await new Promise(resolve => setTimeout(resolve, 1000)); // 1ç§’å¾…æ©Ÿ
        }

      } catch (error) {
        console.error(`âŒ ãƒãƒ£ãƒ³ã‚¯ ${i + 1} ã®å‡¦ç†ã‚¨ãƒ©ãƒ¼:`, error);
        progress.errorCount++;
        
        // ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        processedChunks.push({
          chunkId: chunk.id,
          processedText: chunk.text
        });
      }
    }

    // 3. çµæœã‚’çµ±åˆ
    console.log('ğŸ”„ Step 3: çµæœçµ±åˆä¸­...');
    progress.status = 'merging';
    options.onProgress?.(progress);

    const mergedText = this.chunkingService.mergeChunks(processedChunks, chunkingResult.chunks);

    progress.status = 'completed';
    options.onProgress?.(progress);

    return {
      processedText: mergedText,
      provider: options.provider,
      model: options.model,
      processingTime: 0, // å¾Œã§è¨­å®š
      chunkingResult,
      totalChunks: chunkingResult.totalChunks
    };
  }

  /**
   * é€šå¸¸ã®å˜ä¸€å‡¦ç†
   */
  private async processSingle(
    inputText: string,
    prompt: string,
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    switch (options.provider) {
      case 'gemini':
        return await this.processWithGemini(inputText, prompt, options);
      case 'openai':
        return await this.processWithOpenAI(inputText, prompt, options);
      case 'mock':
        return await this.processWithMock(inputText, prompt, options);
      default:
        return await this.processOffline(inputText, prompt, options);
    }
  }

  /**
   * æ®‹ã‚Šæ™‚é–“ã®æ¨å®šè¨ˆç®—
   */
  private calculateEstimatedTime(processed: number, total: number, startTime: number): number {
    if (processed === 0) return 0;
    
    const elapsed = Date.now() - startTime;
    const averageTime = elapsed / processed;
    const remaining = total - processed;
    
    return Math.round((remaining * averageTime) / 1000); // ç§’å˜ä½ã§è¿”ã™
  }

  /**
   * Gemini APIã‚’ä½¿ç”¨ã—ãŸå‡¦ç†
   */
  private async processWithGemini(
    text: string, 
    prompt: string, 
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    let apiKey = await this.secureStorage.getCredential('gemini_api_key');
    
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
    if (!apiKey) {
      apiKey = process.env.GEMINI_API_KEY || process.env.VITE_GEMINI_API_KEY;
      console.log('ğŸ”‘ Using Gemini API key from environment variables');
    }
    
    if (!apiKey) {
      throw new Error('Gemini API key not found in SecureStorage or environment variables');
    }

    const request = {
      contents: [{
        parts: [{ text: `${prompt}\n\n${text}` }]
      }],
      generationConfig: {
        temperature: options.temperature,
        maxOutputTokens: options.maxTokens
      }
    };

    const response = await axios.post(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`,
      request,
      {
        headers: { 'Content-Type': 'application/json' },
        timeout: options.timeout
      }
    );

    if (!response.data.candidates?.[0]?.content?.parts?.[0]?.text) {
      throw new Error('Invalid Gemini API response');
    }

    return {
      processedText: response.data.candidates[0].content.parts[0].text.trim(),
      provider: 'gemini',
      model: 'gemini-2.0-flash',
      processingTime: 0
    };
  }

  /**
   * OpenAI APIã‚’ä½¿ç”¨ã—ãŸå‡¦ç†
   */
  private async processWithOpenAI(
    text: string, 
    prompt: string, 
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    let apiKey = await this.secureStorage.getCredential('openai_api_key');
    
    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’å–å¾—
    if (!apiKey) {
      apiKey = process.env.OPENAI_API_KEY || process.env.VITE_OPENAI_API_KEY;
      console.log('ğŸ”‘ Using OpenAI API key from environment variables');
    }
    
    if (!apiKey) {
      throw new Error('OpenAI API key not found in SecureStorage or environment variables');
    }

    const request = {
      model: options.model || 'gpt-5',
      messages: [
        { role: 'system', content: prompt },
        { role: 'user', content: text }
      ],
      temperature: options.temperature,
      max_tokens: options.maxTokens
    };

    const response = await axios.post(
      'https://api.openai.com/v1/chat/completions',
      request,
      {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        timeout: options.timeout
      }
    );

    if (!response.data.choices?.[0]?.message?.content) {
      throw new Error('Invalid OpenAI API response');
    }

    return {
      processedText: response.data.choices[0].message.content.trim(),
      provider: 'openai',
      model: options.model || 'gpt-5',
      tokens: response.data.usage?.total_tokens,
      processingTime: 0
    };
  }

  /**
   * ãƒ¢ãƒƒã‚¯å‡¦ç†ï¼ˆãƒ‡ãƒ¢ãƒ»ãƒ†ã‚¹ãƒˆç”¨ï¼‰
   */
  private async processWithMock(
    text: string, 
    prompt: string, 
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    // 1-3ç§’ã®æ“¬ä¼¼å‡¦ç†æ™‚é–“
    await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 2000));

    const mockResult = this.generateMockResult(text);

    return {
      processedText: mockResult,
      provider: 'mock',
      model: 'mock-ai-v1',
      processingTime: 0
    };
  }

  /**
   * ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰
   */
  private async processOffline(
    text: string, 
    prompt: string, 
    options: AIProcessingOptions
  ): Promise<AIProcessingResult> {
    console.log('ğŸ”§ ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®æ­£ä¸­...');

    let processedText = text;

    // åŸºæœ¬çš„ãªéŸ³å£°èªè­˜ä¿®æ­£
    processedText = this.applyBasicCorrections(processedText);

    // è­°äº‹éŒ²ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåŒ–
    processedText = this.formatAsMinutes(processedText);

    return {
      processedText,
      provider: 'offline',
      model: 'rule-based-v1',
      processingTime: 0
    };
  }

  /**
   * åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆä¿®æ­£ï¼ˆéŸ³å£°èªè­˜ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼‰
   */
  private applyBasicCorrections(text: string): string {
    let corrected = text;

    // è©±ã—è¨€è‘‰ã®å‰Šé™¤
    corrected = corrected.replace(/\b(ãˆãƒ¼ã¨|ã‚ã®ãƒ¼|ãã®ãƒ¼|ã¾ã‚|ã¡ã‚‡ã£ã¨)\b/g, '');
    
    // é‡è¤‡è¡¨ç¾ã®ç°¡ç´ åŒ–
    corrected = corrected.replace(/(.{1,10}?)\1{2,}/g, '$1');
    
    // ä¸€èˆ¬çš„ãªéŸ³å£°èªè­˜èª¤ã‚Šä¿®æ­£
    const corrections = [
      ['ã‹ã‚“ã', 'ä¼šè­°'],
      ['ãã˜ã‚ã', 'è­°äº‹éŒ²'],
      ['ã•ã‚“ã‹ã—ã‚ƒ', 'å‚åŠ è€…'],
      ['ã—ã¤ã‚‚ã‚“', 'è³ªå•'],
      ['ã‹ã„ã¨ã†', 'å›ç­”'],
      ['ã‘ã£ã¦ã„', 'æ±ºå®š'],
      ['ã¤ãã‹ã„', 'æ¬¡å›'],
    ];

    corrections.forEach(([wrong, correct]) => {
      corrected = corrected.replace(new RegExp(wrong, 'g'), correct);
    });

    // æ”¹è¡Œãƒ»ã‚¹ãƒšãƒ¼ã‚¹æ­£è¦åŒ–
    corrected = corrected.replace(/\n{3,}/g, '\n\n');
    corrected = corrected.replace(/[ ]{2,}/g, ' ');
    
    return corrected.trim();
  }

  /**
   * è­°äº‹éŒ²å½¢å¼ã¸ã®å¤‰æ›
   */
  private formatAsMinutes(text: string): string {
    const lines = text.split('\n').filter(line => line.trim());
    let formatted = '';

    formatted += '# ä¼šè­°è­°äº‹éŒ²\n\n';
    formatted += `**ä½œæˆæ—¥æ™‚**: ${new Date().toLocaleDateString('ja-JP')}\n`;
    formatted += `**å‡¦ç†æ–¹å¼**: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†\n\n`;
    formatted += '## ä¼šè­°å†…å®¹\n\n';

    // ç°¡å˜ãªæ§‹é€ åŒ–
    lines.forEach((line, index) => {
      const trimmed = line.trim();
      if (trimmed.length > 10) {
        if (trimmed.includes('è³ªå•') || trimmed.includes('ï¼Ÿ')) {
          formatted += `**Q**: ${trimmed}\n\n`;
        } else if (trimmed.includes('å›ç­”') || trimmed.includes('ç­”ãˆ')) {
          formatted += `**A**: ${trimmed}\n\n`;
        } else {
          formatted += `- ${trimmed}\n`;
        }
      }
    });

    formatted += '\n## å‚™è€ƒ\n\n';
    formatted += 'ã“ã®è­°äº‹éŒ²ã¯ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å‡¦ç†ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚\n';
    formatted += 'å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚\n';

    return formatted;
  }

  /**
   * ãƒ¢ãƒƒã‚¯çµæœç”Ÿæˆ
   */
  private generateMockResult(originalText: string): string {
    const mockHeader = `# ä¼šè­°è­°äº‹éŒ²ï¼ˆãƒ¢ãƒƒã‚¯å‡¦ç†ï¼‰

**æ—¥æ™‚**: ${new Date().toLocaleDateString('ja-JP')}
**å‡¦ç†**: AIæ¨¡æ“¬å‡¦ç†
**å…ƒãƒ†ã‚­ã‚¹ãƒˆé•·**: ${originalText.length}æ–‡å­—

## å‡¦ç†çµæœ

`;

    const mockContent = originalText
      .replace(/ãˆãƒ¼ã¨|ã‚ã®ãƒ¼|ãã®ãƒ¼/g, '')
      .replace(/\n{2,}/g, '\n\n')
      .split('\n')
      .map(line => line.trim())
      .filter(line => line.length > 0)
      .map(line => `- ${line}`)
      .join('\n');

    return mockHeader + mockContent + '\n\n**æ³¨è¨˜**: ã“ã‚Œã¯ãƒ¢ãƒƒã‚¯å‡¦ç†ã«ã‚ˆã‚‹çµæœã§ã™ã€‚';
  }

  /**
   * ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—
   */
  private async getPromptTemplate(templateId: string): Promise<PromptTemplate | null> {
    try {
      const { paths } = await this.workspaceService.resolve();
      console.log('ğŸ” Workspace paths:', JSON.stringify(paths, null, 2));
      
      if (!paths.templates) {
        console.error('âŒ templates path is undefined:', paths);
        console.log('ğŸ”„ Using fallback template path...');
        
        // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç›´æ¥ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
        const { root } = await this.workspaceService.resolve();
        const fallbackTemplatePath = path.join(root, 'templates', `${templateId}.json`);
        console.log('ğŸ“ Fallback template path:', fallbackTemplatePath);
        
        const content = await fs.readFile(fallbackTemplatePath, 'utf-8');
        return JSON.parse(content) as PromptTemplate;
      }
      
      const templatePath = path.join(paths.templates, `${templateId}.json`);
      console.log('ğŸ“ Template path:', templatePath);
      
      const content = await fs.readFile(templatePath, 'utf-8');
      return JSON.parse(content) as PromptTemplate;
    } catch (error) {
      console.warn(`ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ ${templateId} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“:`, error);
      return null;
    }
  }

  /**
   * ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
   */
  private getDefaultPrompt(): string {
    return `ã‚ãªãŸã¯å°‚é–€çš„ãªè­°äº‹éŒ²ç·¨é›†è€…ã§ã™ã€‚ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ä¿®æ­£ãƒ«ãƒ¼ãƒ«:
- èª¤å­—è„±å­—ã‚’ä¿®æ­£
- è©±ã—è¨€è‘‰ã‚’è‡ªç„¶ãªæ–‡ç« ã«å¤‰æ›
- æ§‹é€ åŒ–ã•ã‚ŒãŸè­°äº‹éŒ²å½¢å¼ã«æ•´ç†
- Markdownå½¢å¼ã§å‡ºåŠ›

ä½™è¨ˆãªèª¬æ˜ã¯å«ã‚ãšã€ä¿®æ­£ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆå†ä¿®æ­£
   */
  async reviseText(
    originalText: string, 
    revisionNotes: string, 
    options?: Partial<AIProcessingOptions>
  ): Promise<AIProcessingResult> {
    const revisionPrompt = `ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã€æŒ‡å®šã•ã‚ŒãŸä¿®æ­£æŒ‡ç¤ºã«å¾“ã£ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ä¿®æ­£æŒ‡ç¤º: ${revisionNotes}

ä¿®æ­£å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:
${originalText}

ä¿®æ­£æŒ‡ç¤ºã«æ­£ç¢ºã«å¾“ã„ã€Markdownãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;

    return await this.processText('', 'revision', revisionPrompt, options);
  }

  /**
   * åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ä¸€è¦§å–å¾—
   */
  async getAvailableProviders(): Promise<string[]> {
    const providers = ['offline', 'mock'];
    
    // API ã‚­ãƒ¼ã®å­˜åœ¨ç¢ºèª
    try {
      const geminiKey = await this.secureStorage.getCredential('gemini_api_key');
      if (geminiKey) providers.push('gemini');
      
      const openaiKey = await this.secureStorage.getCredential('openai_api_key');
      if (openaiKey) providers.push('openai');
    } catch (error) {
      console.warn('API ã‚­ãƒ¼ç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼:', error);
    }
    
    return providers;
  }
}